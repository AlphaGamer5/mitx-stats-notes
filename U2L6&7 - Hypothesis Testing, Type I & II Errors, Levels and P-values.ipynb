{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 2 Lectures 6 and 7 - Hypothesis Testing, Type I & II Error, Levels, and P-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Asking binary questions of data in the form of the null hypothesis and the alternative hypothesis, which [suggest no effect or reinforce the status quo], and [suggest an effect or reject the status quo], respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Assumptions\n",
    "\n",
    "Assumptions simplify the model to a family/families of distributions...\n",
    "\n",
    "$X_1, ..., X_n$ i.i.d. Poisson($\\lambda$)\n",
    "\n",
    "... in disjoint hypothesis spaces. \n",
    "\n",
    "$H_0: \\lambda \\in \\Theta_0$\n",
    "\n",
    "$H_A: \\lambda \\in \\Theta_1$\n",
    "\n",
    "$\\Theta_0 \\cap \\Theta_1 = \\emptyset$\n",
    "\n",
    "We can impose assumptions based on known status quo or by logical induction. Assumptions can also be made if we only care about a certain kind of result, for example making our hypothesis one-sided if we only care about $\\lambda$ being larger than any status quo $\\lambda_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Sided Hypothesis\n",
    "\n",
    "Rejection interval is to the left <i>or</i> right of the parameter of interest under the null hypothesis, $H_0$. e.g.:\n",
    "\n",
    "$H_0: \\theta \\leq x$\n",
    "\n",
    "$H_A: \\theta > x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Sided Hypothesis\n",
    "\n",
    "Rejection interval is a union of intervals to the left <i>and</i> right of the parameter of interest under the null hypothesis, $H_0$. e.g.: \n",
    "\n",
    "$H_0: \\theta = x$\n",
    "\n",
    "$H_A: \\theta \\neq x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment and Control\n",
    "\n",
    "If the status quo for our specific null hypothesis isn't well-established, we need a two-sample test so we can first establish a baseline - a measurement of random noise unrelated to the effect we expect in our alternate hypothesis. This group of samples is called the <i>control group</i>, and they establish our null hypothesis, $H_0$. The samples that are exposed to <i>treatment</i>, then, are those that have expected outcome in the alternate hypothesis, $H_A$. The <i>treatment effect</i> is the difference between the treatment and control group. But, rather than estimating the effect here, we're only interested in answering the binary question <i>is there a significant difference? And, what is the $level$ of this significance?</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Test Statistic\n",
    "\n",
    "The test statistic seeks to answer the question <i>if the null hypothesis is true, how likely is our parameter estimate?</i> Where does our estimate fall on the standardized distribution of a $\\theta_0 \\in \\Theta_0$?\n",
    "\n",
    "If our hypothesis is one-sided and our null is fixed with some parameter $\\theta_0$ under $H_0$, and standard deviation $\\sigma_0$, and if $H_0$ is true,\n",
    "\n",
    "### $T = \\sqrt{n} \\frac{\\hat{\\theta}_n - \\theta_0}{\\sigma_{0}} \\xrightarrow[n \\to \\infty]{(d)} \\mathcal{N}(0, 1)$\n",
    "\n",
    "... the realization of this statistic is a realization from a standard gaussian.\n",
    "\n",
    "### $T = \\sqrt{n} |\\frac{\\hat{\\theta}_n - \\theta_0}{\\sigma_{0}}|$ \n",
    "\n",
    "... is then our two-sided test-statistic, since it gets the absolute standardized distance of $\\hat{\\theta}_n$ from $\\theta_0$.\n",
    "\n",
    "Question of note: what if $\\theta_0$ isn't fixed? If $\\sigma_{0}$ is estimated by $\\hat{\\theta}_n$, what is $\\sigma_0$ in relation to $\\hat{\\theta}_n$ asymptotically (as $n \\to \\infty$)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Test\n",
    "\n",
    "$\\psi$ is any indicator function designed to output [1] or [0], signifying [reject $H_0$] or [fail to reject $H_0$], with input $\\{X_1, ..., X_n\\}$, the set of our sample. You can see it as converting your test statistic (<i>how likely is this set a set of realizations if $H_0$ is true?</i>) into an answer to the question <i>is the distance from $\\theta_0$ large enough to reject it?</i> Our test can be anything, but to make it a good one, we need to be thoughtful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which $\\theta_0 \\in \\Theta_0$?\n",
    "\n",
    "### Type I Error, $\\alpha_{\\psi}$\n",
    "\n",
    "The probability of a false positive, or:\n",
    "\n",
    "$\\mathbb{P}(\\psi = 1$ and $\\theta \\in \\Theta_0)$\n",
    "\n",
    "### Type II Error, $\\beta_{\\psi}$\n",
    "\n",
    "The probability of a false negative, or:\n",
    "\n",
    "$\\mathbb{P}(\\psi = 0$ and $\\theta \\in \\Theta_1)$\n",
    "\n",
    "### Choosing $\\theta_0$ based on error\n",
    "\n",
    "Consider\n",
    "\n",
    "$H_0: \\theta \\leq x$\n",
    "\n",
    "$H_A: \\theta > x$\n",
    "\n",
    "As $\\theta_0$ moves closer to $x$ from the left, its distribution moves with it, which increases $\\alpha$ since realizations overlap with realizations of distributions beyond $x$ - those with $\\theta_1 \\in \\Theta_1$ that might give $\\psi = 1$. \n",
    "\n",
    "At $\\theta_0 = x$, $\\alpha_{\\psi}$ is at its maximum. But, more importantly, the so is the...\n",
    "\n",
    "### <b>power</b>\n",
    "\n",
    "$\\pi_{\\psi} = inf_{\\theta_1}(1 - \\beta_{\\psi}(\\theta))$\n",
    "\n",
    "... which is the probability of rejecting a false $H_0$. This makes $x$ the ideal $\\theta_0$\n",
    "\n",
    "Note: \n",
    "\n",
    "$inf$ $(0, 2] = 0$\n",
    "\n",
    "$min$ $(0, 2] \\neq 0$\n",
    "\n",
    "... which allows us to include a $\\theta_0$ in our power calculation as if it were a $\\theta_1$\n",
    "\n",
    "## Level $\\alpha$\n",
    "\n",
    "To reduce our type I error $\\alpha_{\\psi}$, we need to put a buffer around $x$. How big? $\\alpha_{\\psi} = 0$ if $\\psi = 1$ is unattainable. All we have to do is move the rejection goalpost so far away that our estimate $\\hat{\\theta}_n$ will never match it. \n",
    "\n",
    "Our test has level $\\alpha$ if:\n",
    "\n",
    "- $\\mathbb{P}(\\psi = 1$ and $\\theta \\in \\Theta_0) \\leq \\alpha$\n",
    "\n",
    "or, more compact:\n",
    "\n",
    "- $\\alpha_{\\psi} \\leq \\alpha$\n",
    "\n",
    "Where $\\alpha$ is the smallest upper bound for this probability. This means the probability of type I error is at most $\\alpha$. Note level $\\alpha$ is dependent on all $\\alpha_{\\psi}$, which means if $\\psi$ changes or $\\Theta_0$ changes, so does level $\\alpha$.\n",
    "\n",
    "Assuming the one-sided test from the previous section, $1 - \\Phi(T)$ is our $\\alpha_{\\psi}$, or type I error, since we're assuming $\\hat{\\theta}_n$ is an estimate of parameter $\\theta_0$. So, $\\psi = 1$ at level $\\alpha$ if...\n",
    "\n",
    "- $T \\geq q_{\\alpha}$ for all $\\theta_0 \\in \\Theta_0$ (assumes the one sided test from the previous section)\n",
    "\n",
    "In our test, $\\theta_0 = x$, where $\\alpha_{\\psi}$ is maximized, so we don't have to worry about all of $\\Theta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value\n",
    "\n",
    "This is the probability of a realization of a standard gaussian being at least as far from the mean (0) as $T$. It quantifies our confidence in rejecting the null - the smaller the better.\n",
    "\n",
    "Continuing with the aforementioned one-sided hypothesis, we get our p-value from the simple statistic\n",
    "\n",
    "- $1 - \\Phi(T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizations will go here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
